# https://hub.docker.com/r/nvidia/cuda/tags
# Select the tag that matches the CUDA version on the host.
# Make sure to select a CuDNN image!
# See the compatibility matrix here: https://docs.nvidia.com/deploy/cuda-compatibility/index.html#use-the-right-compat-package
# Also make sure to change the fix at the very end of this file.
FROM nvidia/cuda:12.2.2-cudnn8-devel-ubuntu22.04

# Prevent interactive prompts during build
ENV DEBIAN_FRONTEND=noninteractive

# Install Python 3.11 and pip3
RUN apt update \
    && apt install --fix-missing -y software-properties-common \
    && add-apt-repository -y ppa:deadsnakes/ppa \
    && apt install --fix-missing -y python3.11 python3.11-venv python3.11-dev python3-pip curl vim less openssh-client \
    && rm -f /usr/bin/python /usr/bin/python3 \
    && ln -s $(which python3.11) /usr/bin/python \
    && ln -s $(which python3.11) /usr/bin/python3

# Switch to a non-root user
# Dev containers should substitute for the current user on startup but that doesn't work: https://code.visualstudio.com/remote/advancedcontainers/add-nonroot-user
RUN groupadd -g 1000 cora \
    && useradd -m -u 1000 -g cora cora \
    # Allow the user to install packages
    && chmod -R a+rwx /usr/local /usr/include/python3.11
USER cora:cora
WORKDIR /home/cora/workspace

# Install pip and setuptools first
RUN python -m pip install --upgrade pip setuptools wheel

# Install UV package manager using pip (more reliable method for Docker)
RUN python -m pip install uv

# Add UV to PATH and set environment variables
ENV PATH="$PATH:/home/cora/.local/bin" \
    # Prevent JAX from allocating 90% of GPU memory:
    XLA_PYTHON_CLIENT_PREALLOCATE="false" \
    # Set XLA version to match CUDA driver
    XLA_CUDA_VERSION="12.4.0"

# Copy the entire project
COPY --chown=cora:cora . .

# Create simple scripts to extract dependencies with proper version format
RUN echo 'import tomli\n\ndef convert_version(v):\n    if v.startswith("^"):\n        return ">=" + v[1:]\n    return v\n\nwith open("pyproject.toml", "rb") as f:\n    config = tomli.load(f)\n\ndeps = [(k, convert_version(v)) for k, v in config["tool"]["poetry"]["dependencies"].items() \n       if k not in ["python", "jax", "jaxlib", "torch", "torchvision", "torchaudio", "matplotlib"]]\n\nwith open("requirements.txt", "w") as out:\n    out.write("\\n".join([f"{k}{v}" for k, v in deps]))' > extract_deps.py \
    && echo 'import tomli\n\ndef convert_version(v):\n    if v.startswith("^"):\n        return ">=" + v[1:]\n    return v\n\nwith open("pyproject.toml", "rb") as f:\n    config = tomli.load(f)\n\ntry:\n    dev_deps = [(k, convert_version(v)) for k, v in config["tool"]["poetry"]["group"]["dev"]["dependencies"].items()]\nexcept (KeyError, TypeError):\n    dev_deps = []\n\nwith open("dev-requirements.txt", "w") as out:\n    out.write("\\n".join([f"{k}{v}" for k, v in dev_deps]))' > extract_dev_deps.py

# First upgrade pip to latest
RUN python -m pip install --upgrade pip

# Install tomli and extract dependencies
RUN python -m pip install tomli \
    && python extract_deps.py \
    && python extract_dev_deps.py

# Install dependencies from requirements.txt
RUN python -m uv pip install -r requirements.txt \
    && python -m uv pip install -r dev-requirements.txt || true

# Install local package in development mode
RUN python -m uv pip install -e ./

# Install PyTorch (CPU version as we are using JAX for GPU PyTorch is only for dataloader utilities)
RUN python -m uv pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cpu

# Remove any existing JAX installations
RUN python -m uv pip uninstall -y jax jaxlib || true

# Install other specific dependencies
RUN python -m uv pip install matplotlib==3.8.2 \
    && python -m uv pip install flax==0.9.0 einops==0.8.1 \
    && python -m uv pip install equinox==0.11.7 optax==0.2.3 wandb==0.19.8 imageio==2.37.0 imageio-ffmpeg==0.6.0

# Install specific JAX versions for CUDA
RUN python -m uv pip install "jax[cuda12]==0.4.33" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html





