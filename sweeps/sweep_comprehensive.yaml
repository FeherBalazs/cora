program: examples/debug_transformer_wandb.py
method: random
run_cap: 400  # Extensive search with 400 experiments
metric:
  goal: maximize
  name: best_probe_accuracy
parameters:
  # Base configuration
  config:
    value: "6block"
  
  # ARCHITECTURE SEARCH - now we can afford to explore!
  num_blocks:
    values: [3, 4, 5, 6, 7, 8]  # Comprehensive architecture search
  
  hidden_size:
    values: [48, 64, 96, 128]   # Multiple sizes
  
  # MULTIPLE SEEDS for statistical robustness
  seed:
    values: [10, 20, 30, 42, 123]  # 5 seeds for better statistics
  
  # PRIMARY SEARCH - L1/L2 regularization (extended range)
  intermediate_l1_coeff:
    distribution: log_uniform_values
    min: 0.000001  # Very small values
    max: 0.5       # Extended to larger values
  
  intermediate_l2_coeff:
    distribution: log_uniform_values  
    min: 0.000001  # Very small values
    max: 0.5       # Extended to larger values
  
  # LEARNING RATE OPTIMIZATION
  peak_lr_hidden:
    distribution: log_uniform_values
    min: 0.01
    max: 0.3
  
  peak_lr_weights:
    distribution: log_uniform_values
    min: 0.0001
    max: 0.01
  
  # INFERENCE OPTIMIZATION
  inference_lr_scale_base:
    distribution: uniform
    min: 0.5
    max: 2.5
  
  inference_steps:
    values: [10, 15, 20, 25, 30, 40]
  
  # OPTIMIZATION PARAMETERS
  hidden_momentum:
    values: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]
  
  h_grad_clip_norm:
    distribution: uniform
    min: 500.0
    max: 5000.0
    
  w_grad_clip_norm:
    distribution: uniform
    min: 100.0
    max: 2000.0
  
  # ARCHITECTURE DETAILS
  num_heads:
    values: [1, 2, 4]  # Explore different attention heads
  
  mlp_ratio:
    values: [2.0, 4.0, 6.0]  # Different MLP expansion ratios
  
  # TRAINING DYNAMICS
  use_lr_schedule_h:
    values: [true, false]
  
  use_lr_schedule_w:
    values: [true, false]
  
  warmup_steps:
    values: [0, 50, 100]
  
  # NORMALIZATION EXPERIMENTS
  use_vode_state_layernorm:
    values: [true, false]
  
  use_adamw_for_hidden_optimizer:
    values: [true, false]
  
  # CORRUPTION EXPERIMENTS
  corrupt_ratio:
    values: [0.15, 0.25, 0.35, 0.5]
  
  use_lower_half_mask:
    values: [true, false]
  
  # TRAINING SETTINGS (longer for better evaluation)
  epochs:
    value: 25  # Longer epochs for quality results
  theta:
    values: [1000, 10000, 50000]  # Different positional encoding
  use_ssl_augmentations:
    values: [true, false]
  use_cifar10_norm:
    values: [true, false]
  
  # LARGER DATASETS for better evaluation
  num_images:
    value: 3
  test_subset:
    value: 1000  # Much larger test set
  train_subset:
    value: 50000  # Full CIFAR-10 training set
  
  # FIXED PARAMETERS
  batch_size:
    value: 200
  patch_size:
    value: 4
  hidden_lr_inference:
    value: 0.095
  reconstruction_every_n_epochs:
    value: 10
  validation_every_n_epochs:
    value: 5
  use_inference_lr_scaling:
    value: true
  weight_decay:
    value: 0.0002
  use_noise:
    value: true
  update_weights_every_inference_step:
    value: false
  use_early_stopping:
    value: true
  early_stopping_patience:
    value: 8  # Reasonable patience for 25 epochs
  early_stopping_min_delta:
    value: 0.001
  early_stopping_metric:
    value: "train_mse"
  save_model_train_mse_threshold:
    value: 0.009
  model_saving_metric:
    value: "train_mse"
  use_vode_grad_norm:
    value: false
  inference_clamp_alpha:
    value: 1.0
  save_reconstruction_images:
    value: true
  save_reconstruction_video:
    value: false  # Disable to save time
  video_fps:
    value: 5
  reinitialize_model_for_each_epoch:
    value: false
  use_status_init_in_training:
    value: false
  use_status_init_in_unmasking:
    value: false
  lr_schedule_min_lr_factor:
    value: 0.5
  linear_probe_every_n_epochs:
    value: 5
  linear_probe_vode_indices:
    value: "0"
  linear_probe_concatenate_features:
    value: true
  linear_probe_use_gap:
    value: true
  linear_probe_lr:
    value: 0.001
  linear_probe_wd:
    value: 0.0001
  linear_probe_epochs:
    value: 20
  linear_probe_batch_size:
    value: 200
  linear_probe_seed:
    value: 123 