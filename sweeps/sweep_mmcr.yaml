program: examples/debug_transformer_wandb.py
method: bayes
metric:
  goal: maximize
  name: best_probe_accuracy

parameters:
  config:
    value: "6block"
  # --- Bayesian Search Parameters ---
  use_mmcr_loss:
    value: True
  mmcr_loss_scale_factor:
    distribution: log_uniform_values
    min: 0.005
    max: 0.05
  mmcr_vode_indices:
    values: ["0", "0,1,2,3,4,5,6,7", "0,1,4,7"]
  mmcr_lambda:
    values: [0.0, 0.05, 0.1]
  batch_size:
    value: 64
  num_views_per_image:
    value: 8
  num_heads:
    value: 1
  peak_lr_hidden: # Mapped from lr_hidden_candidates
    distribution: uniform
    min: 0.01
    max: 0.1
  inference_lr_scale_base:
    distribution: uniform
    min: 1.05
    max: 1.25
  hidden_momentum:
    distribution: uniform
    min: 0.1
    max: 0.95
  seed:
    values: [20, 30] # As per the last update in your hyperparam_search.py
  h_grad_clip_norm:
    value: 2000
  inference_steps:
    value: 20
  warmup_steps:
    value: 0
  w_grad_clip_norm:
    value: 500.0
  use_vode_state_layernorm:
    value: False
  intermediate_l1_coeff:
    value: 0.0
  intermediate_l2_coeff:
    value: 0.0

  # Fixed Parameters (from fixed_overrides, not in search)
  epochs:
    value: 1
  validation_subset:
    value: 1000
  theta:
    value: 10000
  use_ssl_augmentations:
    value: True
  use_cifar10_norm:
    value: True
  num_images:
    value: 3
  test_subset:
    value: 10000
  train_subset:
    value: 50000
  peak_lr_weights:
    value: 0.001
  hidden_lr_inference:
    value: 0.095
  reconstruction_every_n_epochs:
    value: 25
  validation_every_n_epochs:
    value: 25
  use_inference_lr_scaling:
    value: True
  use_lr_schedule_w:
    value: False
  use_lr_schedule_h:
    value: False
  weight_decay:
    value: 0.0002
  mlp_ratio:
    value: 4.0
  patch_size:
    value: 4
  use_noise:
    value: True
  update_weights_every_inference_step:
    value: False
  use_early_stopping:
    value: True
  early_stopping_patience:
    value: 25
  early_stopping_min_delta:
    value: 0.001
  early_stopping_metric:
    value: "train_mse"
  save_model_train_mse_threshold:
    value: 0.008
  model_saving_metric:
    value: "train_mse"
  use_vode_grad_norm:
    value: False
  use_adamw_for_hidden_optimizer:
    value: False
  corrupt_ratio:
    value: 0.25
  use_lower_half_mask:
    value: False
  inference_clamp_alpha:
    value: 1.0
  save_reconstruction_images:
    value: True
  save_reconstruction_video:
    value: True
  video_fps:
    value: 5
  reinitialize_model_for_each_epoch:
    value: False
  use_status_init_in_training:
    value: False
  use_status_init_in_unmasking:
    value: False
  lr_schedule_min_lr_factor:
    value: 0.5

  # Fixed Linear Probing Parameters
  linear_probe_every_n_epochs:
    value: 1
  linear_probe_vode_indices:
    value: "0,1,4,7"
  linear_probe_concatenate_features:
    value: True
  linear_probe_use_gap:
    value: True
  linear_probe_lr:
    value: 0.001
  linear_probe_wd:
    value: 0.0001
  linear_probe_epochs:
    value: 50
  linear_probe_batch_size:
    value: 512
  linear_probe_seed:
    value: 123